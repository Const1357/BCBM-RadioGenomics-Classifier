{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8a8716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_image_and_mask_compare(\n",
    "    img_orig, mask_orig, img_aug, mask_aug,\n",
    "    title=\"Image + Mask Animation (Original vs Predicted)\",\n",
    "    alpha=0.4, interval=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Animate a 3D image with a red mask overlay, comparing original and augmented side by side.\n",
    "\n",
    "    Args:\n",
    "        img_orig (np.ndarray): Original 3D image array (Z last, e.g. [H, W, Z]).\n",
    "        mask_orig (np.ndarray): Original 3D mask array (same shape as img, binary or float).\n",
    "        img_aug (np.ndarray): Augmented 3D image array (Z last, e.g. [H, W, Z]).\n",
    "        mask_aug (np.ndarray): Augmented 3D mask array (same shape as img, binary or float).\n",
    "        title (str): Title prefix for the animation.\n",
    "        alpha (float): Alpha value for mask overlay.\n",
    "        interval (int): Delay between frames in ms.\n",
    "\n",
    "    Returns:\n",
    "        HTML: Animation for Jupyter display.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import animation\n",
    "    from IPython.display import HTML\n",
    "    import numpy as np\n",
    "\n",
    "    # Optionally normalize images for display\n",
    "    # img_orig_norm = (img_orig - img_orig.min()) / (np.ptp(img_orig) + 1e-8)\n",
    "    # img_aug_norm = (img_aug - img_aug.min()) / (np.ptp(img_aug) + 1e-8)\n",
    "    img_orig_norm = img_orig\n",
    "    img_aug_norm = img_aug\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    slice_idx = img_orig.shape[2] // 2\n",
    "\n",
    "    # Initial slices\n",
    "    img_slice_orig = img_orig_norm[:, :, slice_idx]\n",
    "    mask_slice_orig = mask_orig[:, :, slice_idx]\n",
    "    img_slice_aug = img_aug_norm[:, :, slice_idx]\n",
    "    mask_slice_aug = mask_aug[:, :, slice_idx]\n",
    "\n",
    "    # Original\n",
    "    axes[0].set_title(f\"Original (slice {slice_idx})\")\n",
    "    im_orig = axes[0].imshow(img_slice_orig, cmap='gray')\n",
    "    red_mask_orig = np.zeros((*mask_slice_orig.shape, 4), dtype=np.float32)\n",
    "    red_mask_orig[..., 0] = 1.0\n",
    "    red_mask_orig[..., 3] = (mask_slice_orig > 0) * alpha\n",
    "    mask_im_orig = axes[0].imshow(red_mask_orig)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Augmented\n",
    "    axes[1].set_title(f\"Predicted (slice {slice_idx})\")\n",
    "    im_aug = axes[1].imshow(img_slice_aug, cmap='gray')\n",
    "    red_mask_aug = np.zeros((*mask_slice_aug.shape, 4), dtype=np.float32)\n",
    "    red_mask_aug[..., 0] = 1.0\n",
    "    red_mask_aug[..., 3] = (mask_slice_aug > 0) * alpha\n",
    "    mask_im_aug = axes[1].imshow(red_mask_aug)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    def update(i):\n",
    "        # Original\n",
    "        img_slice_orig = img_orig_norm[:, :, i]\n",
    "        mask_slice_orig = mask_orig[:, :, i]\n",
    "        im_orig.set_data(img_slice_orig)\n",
    "        red_mask_orig = np.zeros((*mask_slice_orig.shape, 4), dtype=np.float32)\n",
    "        red_mask_orig[..., 0] = 1.0\n",
    "        red_mask_orig[..., 3] = (mask_slice_orig > 0) * alpha\n",
    "        mask_im_orig.set_data(red_mask_orig)\n",
    "        axes[0].set_title(f\"Original (slice {i})\")\n",
    "\n",
    "        # Augmented\n",
    "        img_slice_aug = img_aug_norm[:, :, i]\n",
    "        mask_slice_aug = mask_aug[:, :, i]\n",
    "        im_aug.set_data(img_slice_aug)\n",
    "        red_mask_aug = np.zeros((*mask_slice_aug.shape, 4), dtype=np.float32)\n",
    "        red_mask_aug[..., 0] = 1.0\n",
    "        red_mask_aug[..., 3] = (mask_slice_aug > 0) * alpha\n",
    "        mask_im_aug.set_data(red_mask_aug)\n",
    "        axes[1].set_title(f\"Predicted (slice {i})\")\n",
    "\n",
    "        return [im_orig, mask_im_orig, im_aug, mask_im_aug]\n",
    "\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig, update, frames=img_orig.shape[2], interval=interval, blit=True\n",
    "    )\n",
    "    plt.close(fig)\n",
    "    return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7171a50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model: trial_32\n",
      "torch.Size([25155])\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0511, device='cuda:0', grad_fn=<StdBackward0>) tensor(-0.1290, device='cuda:0', grad_fn=<MinBackward1>) tensor(0.1337, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      "Evaluating model: trial_46\n",
      "torch.Size([25155])\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0509, device='cuda:0', grad_fn=<StdBackward0>) tensor(-0.1315, device='cuda:0', grad_fn=<MinBackward1>) tensor(0.1320, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      "Evaluating model: trial_27\n",
      "torch.Size([25155])\n",
      "tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0512, device='cuda:0', grad_fn=<StdBackward0>) tensor(-0.1290, device='cuda:0', grad_fn=<MinBackward1>) tensor(0.1377, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      "Evaluating model: trial_43\n",
      "torch.Size([25155])\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0', grad_fn=<StdBackward0>) tensor(-0.1378, device='cuda:0', grad_fn=<MinBackward1>) tensor(0.1375, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      "Evaluating model: trial_42\n",
      "torch.Size([25155])\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0513, device='cuda:0', grad_fn=<StdBackward0>) tensor(-0.1329, device='cuda:0', grad_fn=<MinBackward1>) tensor(0.1354, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.constants import *\n",
    "from model_definitions.UNet import UNet3D\n",
    "\n",
    "from utils.MRIDataset import MRIDataset\n",
    "from utils.transformations import MRIAugmentationPipeline\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "# --------------------------\n",
    "# Load test dataset\n",
    "# --------------------------\n",
    "TRAIN_DATASET = MRIDataset(f\"../{TRAIN_IMG_DIR}\", f\"../{TRAIN_LABEL_FILE}\", is_train=True, augmentations=None)\n",
    "# TEST_DATASET = MRIDataset(VAL_IMG_DIR, VAL_LABEL_FILE, is_train=False, augmentations=None)\n",
    "train_loader = DataLoader(TRAIN_DATASET, batch_size=1, shuffle=False)\n",
    "\n",
    "models = ['trial_32', 'trial_46', 'trial_27', 'trial_43', 'trial_42']   # same 5 top models\n",
    "state_dicts = {m: torch.load(f\"../{EXPERIMENT_DIR}/UNet3D/{m}/model.pt\", map_location=DEVICE) for m in models}\n",
    "\n",
    "for model_name in models:\n",
    "    print(f\"\\nEvaluating model: {model_name}\")\n",
    "\n",
    "    model = UNet3D(depth=5, base_filters=16, clf_threshold=[0.5, 0.5, 0.5]).to(DEVICE, DTYPE)\n",
    "    model.load_state_dict(state_dicts[model_name])\n",
    "    model.eval()\n",
    "\n",
    "    img, mask, label = next(islice(train_loader, 10, 12))\n",
    "\n",
    "    # model.train()\n",
    "    # assert(model.training)\n",
    "    # _, mask_pred = model(img)\n",
    "\n",
    "    # feats, _ = model.encoder(img)\n",
    "    # gap = torch.nn.AdaptiveAvgPool3d(1)\n",
    "    # flat = torch.nn.Flatten()\n",
    "    # feats = flat(gap(feats))\n",
    "    # print(feats.mean(), feats.std())\n",
    "\n",
    "    all_weights = torch.cat([p.flatten() for p in model.classifier.parameters()])\n",
    "    print(all_weights.shape)\n",
    "    print(all_weights.mean(), all_weights.std(), all_weights.min(), all_weights.max())\n",
    "\n",
    "\n",
    "    # img = img.cpu().squeeze(0).squeeze(0).permute(2,1,0).numpy()\n",
    "    # mask = mask.cpu().squeeze(0).squeeze(0).permute(2,1,0).numpy()\n",
    "    # mask_pred = mask_pred.detach().cpu().squeeze(0).squeeze(0).permute(2,1,0).numpy()\n",
    "\n",
    "\n",
    "    # display(animate_image_and_mask_compare(img, mask, img, mask_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCBM_classifier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
